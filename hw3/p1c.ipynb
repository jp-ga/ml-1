{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. (c) We have provided a dataset from taxi trips taken in NYC in taxi trips.parquet. It contains 8 total columns, 7 features and 1 target (trip duration). De ne a multi-layer perceptron in PyTorch or Jax that outputs a conditional mean and variance, and  t this on the taxi trip dataset. Make sure to follow best practices: de ne a baseline (or multiple) baseline models that you think your model should beat, split your dataset into training/validation/test sets, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>min_of_day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>187173</th>\n",
       "      <td>0.270744</td>\n",
       "      <td>1.425051</td>\n",
       "      <td>0.466831</td>\n",
       "      <td>0.776192</td>\n",
       "      <td>-0.007192</td>\n",
       "      <td>-0.942057</td>\n",
       "      <td>-1.047619</td>\n",
       "      <td>1.180855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179655</th>\n",
       "      <td>0.085681</td>\n",
       "      <td>0.306079</td>\n",
       "      <td>-0.226274</td>\n",
       "      <td>0.124111</td>\n",
       "      <td>0.370803</td>\n",
       "      <td>0.778703</td>\n",
       "      <td>-1.047619</td>\n",
       "      <td>-0.311290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120048</th>\n",
       "      <td>-0.555533</td>\n",
       "      <td>-0.934806</td>\n",
       "      <td>-0.022489</td>\n",
       "      <td>-0.548561</td>\n",
       "      <td>-0.434735</td>\n",
       "      <td>-1.183016</td>\n",
       "      <td>-1.047619</td>\n",
       "      <td>1.316504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62587</th>\n",
       "      <td>0.069718</td>\n",
       "      <td>0.035804</td>\n",
       "      <td>0.258900</td>\n",
       "      <td>0.317284</td>\n",
       "      <td>-0.811614</td>\n",
       "      <td>-0.908008</td>\n",
       "      <td>0.481657</td>\n",
       "      <td>0.018144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212063</th>\n",
       "      <td>-0.234482</td>\n",
       "      <td>0.074616</td>\n",
       "      <td>0.115836</td>\n",
       "      <td>0.258310</td>\n",
       "      <td>0.480548</td>\n",
       "      <td>1.066806</td>\n",
       "      <td>-0.537860</td>\n",
       "      <td>0.521985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519591</th>\n",
       "      <td>-0.853230</td>\n",
       "      <td>-0.623528</td>\n",
       "      <td>-1.257638</td>\n",
       "      <td>-0.858561</td>\n",
       "      <td>-0.496274</td>\n",
       "      <td>1.548723</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>1.665317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342999</th>\n",
       "      <td>0.623131</td>\n",
       "      <td>0.373217</td>\n",
       "      <td>-0.558609</td>\n",
       "      <td>-0.119350</td>\n",
       "      <td>0.789244</td>\n",
       "      <td>-1.714696</td>\n",
       "      <td>0.481657</td>\n",
       "      <td>-1.745299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157477</th>\n",
       "      <td>-0.226796</td>\n",
       "      <td>-0.595202</td>\n",
       "      <td>-0.527212</td>\n",
       "      <td>-1.051594</td>\n",
       "      <td>0.081328</td>\n",
       "      <td>-1.976608</td>\n",
       "      <td>1.501174</td>\n",
       "      <td>0.056901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432901</th>\n",
       "      <td>-0.226796</td>\n",
       "      <td>0.056775</td>\n",
       "      <td>1.005321</td>\n",
       "      <td>-1.571717</td>\n",
       "      <td>1.210403</td>\n",
       "      <td>1.111331</td>\n",
       "      <td>-0.028101</td>\n",
       "      <td>0.812663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190792</th>\n",
       "      <td>0.249163</td>\n",
       "      <td>0.068043</td>\n",
       "      <td>0.598640</td>\n",
       "      <td>0.689481</td>\n",
       "      <td>0.140342</td>\n",
       "      <td>0.037493</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.851420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>523554 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "187173          0.270744         1.425051           0.466831   \n",
       "179655          0.085681         0.306079          -0.226274   \n",
       "120048         -0.555533        -0.934806          -0.022489   \n",
       "62587           0.069718         0.035804           0.258900   \n",
       "212063         -0.234482         0.074616           0.115836   \n",
       "...                  ...              ...                ...   \n",
       "519591         -0.853230        -0.623528          -1.257638   \n",
       "342999          0.623131         0.373217          -0.558609   \n",
       "157477         -0.226796        -0.595202          -0.527212   \n",
       "432901         -0.226796         0.056775           1.005321   \n",
       "190792          0.249163         0.068043           0.598640   \n",
       "\n",
       "        dropoff_latitude  trip_duration  min_of_day  day_of_week  day_of_year  \n",
       "187173          0.776192      -0.007192   -0.942057    -1.047619     1.180855  \n",
       "179655          0.124111       0.370803    0.778703    -1.047619    -0.311290  \n",
       "120048         -0.548561      -0.434735   -1.183016    -1.047619     1.316504  \n",
       "62587           0.317284      -0.811614   -0.908008     0.481657     0.018144  \n",
       "212063          0.258310       0.480548    1.066806    -0.537860     0.521985  \n",
       "...                  ...            ...         ...          ...          ...  \n",
       "519591         -0.858561      -0.496274    1.548723     0.991416     1.665317  \n",
       "342999         -0.119350       0.789244   -1.714696     0.481657    -1.745299  \n",
       "157477         -1.051594       0.081328   -1.976608     1.501174     0.056901  \n",
       "432901         -1.571717       1.210403    1.111331    -0.028101     0.812663  \n",
       "190792          0.689481       0.140342    0.037493     0.991416     0.851420  \n",
       "\n",
       "[523554 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read parquet file as pandas dataframe\n",
    "df = pq.read_table('taxi_trips.parquet').to_pandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([523554])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define target\n",
    "y = torch.tensor(df['trip_duration'].to_numpy())\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([523554, 7])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define features\n",
    "X = torch.tensor(df.drop(columns=['trip_duration']).to_numpy())\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes:\n",
      "- - - -\n",
      "x_train: torch.Size([366487, 7])\t y_train: torch.Size([366487])\t frac: 70.00%\n",
      "x_test: torch.Size([104711, 7])\t\t y_test: torch.Size([104711])\t frac: 20.00%\n",
      "x_val: torch.Size([52356, 7])\t\t y_val: torch.Size([52356])\t frac: 10.00%\n"
     ]
    }
   ],
   "source": [
    "# split in training, test and validations\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=10.0/80.0, random_state=1)\n",
    "\n",
    "print('shapes:\\n- - - -')\n",
    "print(f'x_train: {X_train.shape}\\t y_train: {y_train.shape}\\t frac: {y_train.shape[0]/y.shape[0]*100:.2f}%')\n",
    "print(f'x_test: {X_test.shape}\\t\\t y_test: {y_test.shape}\\t frac: {y_test.shape[0]/y.shape[0]*100:.2f}%')\n",
    "print(f'x_val: {X_val.shape}\\t\\t y_val: {y_val.shape}\\t frac: {y_val.shape[0]/y.shape[0]*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model: simple linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# create linear model to predict y from X\n",
    "model_baseline = LinearRegression().fit(X_train, y_train)\n",
    "y_pred_baseline = torch.tensor(model_baseline.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0189)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate r-squared score for baseline model\n",
    "from torcheval.metrics.functional import r2_score\n",
    "r2_score(y_pred_baseline, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss fn and NN model\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, g_vec, y_true):\n",
    "        f_mu = g_vec[:,0]\n",
    "        f_sigma = torch.log(1+torch.exp(g_vec[:,1]))\n",
    "        L = torch.log(f_sigma) + 1/2*(y_true-f_mu)**2/f_sigma**2\n",
    "        return L.mean()\n",
    "\n",
    "class NNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(7, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        g_vec = self.linear_relu_stack(x)\n",
    "        return g_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    # define model\n",
    "    model = NNModel()\n",
    "    # define loss function\n",
    "    loss_fn = MyLoss()\n",
    "    # define optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    # train\n",
    "    for t in range(1000):\n",
    "        # Forward pass: compute predicted y by passing x to the model.\n",
    "        g_vec = model(X_train)\n",
    "\n",
    "        # Compute and print loss.\n",
    "        loss = loss_fn(g_vec, y_train)\n",
    "        if t % 100 == 99:\n",
    "            print(t, loss.item())\n",
    "\n",
    "        # Before the backward pass, use the optimizer object to zero all of the\n",
    "        # gradients for the variables it will update (which are the learnable\n",
    "        # weights of the model)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Calling the step function on an Optimizer makes an update to its parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 0.06182841584086418\n",
      "199 -0.25600045919418335\n",
      "299 -0.3149549663066864\n",
      "399 -0.3442245125770569\n",
      "499 -0.3615590035915375\n",
      "599 -0.3732012212276459\n",
      "699 -0.3820852041244507\n",
      "799 -0.38364002108573914\n",
      "899 -0.394769549369812\n",
      "999 -0.4011291563510895\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7508)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the predicted values using the trained model\n",
    "g_pred = trained_model(X_test)\n",
    "y_pred = g_pred[:,0]\n",
    "sigma_pred = torch.log(1+torch.exp(g_pred[:,1]))\n",
    "\n",
    "# Calculate the R-squared score\n",
    "r2_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the NN had good R2 value from the beginning (0.7508) in comparison to the baseline linear fit (0.0534) on the test dataset, I won't be optimizing hyperparameters. The model performance is good enough for the purposes of this problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. (d) How would we use the model we've just got to predict the probability that a trip will take less than 45 minutes? The normal distribution assumption is fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to transform 45 minutes to the scaling the data used (I won't follow the suggestion on Canvas since scaling the model output to minutes will be easy for the mean but difficult for the variance since it involves a non-linear transformation. It is much easier to transform 45 minutes to the standarized units). We can then use the normal distribution CDF with mean $f_{\\mu}(x)$ and std dev $f_{\\sigma}(x)$ predicted by our model to get $P(y<45 min | X) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. (e) Estimate these probabilities on your held-out test set and report your accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2242358917428096"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_45_minutes_scaled = (np.log(60.0*45.0) - 6.175) / 0.776\n",
    "t_45_minutes_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.99999996, 1.        , ..., 1.        , 0.99999609,\n",
       "       1.        ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "probs_t_less_than_45_minutes = norm.cdf(t_45_minutes_scaled, loc=y_pred.detach().numpy(), scale=sigma_pred.detach().numpy())\n",
    "probs_t_less_than_45_minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(probs_t_less_than_45_minutes, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I can not report an accuracy for the probabilities themselves, since we don't have a 'ground truth' probability nor distribution for the test set. We only have the actual trip durationvalues. What I could is assume that the features of the test set are evenly distributed across the feature domain and calculate the overall probability of the travel being less than 45 mins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9954)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_less_than_45_test_set = (y_test < t_45_minutes_scaled).sum()/len(y_test)\n",
    "prob_less_than_45_test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very close to 1, consistent with what we see in the histogram for the model probabilities. This means the model seems to be accurate ( to be honest, 45 min was just a very large number given the data and transformation that we got, so we expected this probability to be 1 from the beginning and this was not a very elaborate analysis.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
