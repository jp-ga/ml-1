{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Commonly, we instead split the data into a training set, a test set, and a validation set used to select hyperparameters. Use the dataset on wine quality provided `winequality-white.csv` and then divide it randomly into 70% train, 10% validation, and 20% test. The last column “quality” is the target, an integer from 1-10. We’ll view this as a regression problem with mean squared error as the desired loss function. Pick two model classes from the set { RandomForestRegressor, KNeighborsRegressor, MLPRegressor } and read their documentation in Scikit-learn to understand the hyperparameters of these models and what they do. Do grid search over a reasonably-large set of parameters (number of parameter sets > the number of points in the validation set): fit the model on the train set for each set of parameters, and select the “best parameters” using the score on the validation set. Finally, report the performance on the test set for each of the model classes you chose. What’s the relationship between the empirical risk on the validation set and the empirical risk on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load and see data \n",
    "fname = os.path.join('data', 'winequality-white.csv')\n",
    "dset = pd.read_csv(fname, sep=';')\n",
    "dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4898,)\n",
      "(4898, 11)\n"
     ]
    }
   ],
   "source": [
    "# target and features:\n",
    "y = dset.quality\n",
    "X = dset.iloc[:, :-1]\n",
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes:\n",
      "- - - -\n",
      "x_train: (3428, 11)\t y_train: (3428,)\t frac: 69.99%\n",
      "x_test: (980, 11)\t y_test: (980,)\t\t frac: 20.01%\n",
      "x_val: (490, 11)\t y_val: (490,)\t\t frac: 10.00%\n"
     ]
    }
   ],
   "source": [
    "# split in training, test and validations\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=0)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=10.0/80.0, random_state=1)\n",
    "\n",
    "print('shapes:\\n- - - -')\n",
    "print(f'x_train: {X_train.shape}\\t y_train: {y_train.shape}\\t frac: {y_train.shape[0]/y.shape[0]*100:.2f}%')\n",
    "print(f'x_test: {X_test.shape}\\t y_test: {y_test.shape}\\t\\t frac: {y_test.shape[0]/y.shape[0]*100:.2f}%')\n",
    "print(f'x_val: {X_val.shape}\\t y_val: {y_val.shape}\\t\\t frac: {y_val.shape[0]/y.shape[0]*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll start with the multi-layer perceptron regressor using the adam solver and relu activation function. It has many hyperparameters, but the most relevant ones are the number of layers, number of neurons per layer, initial learning rate and batch size. I'll mantain the number of neurons fixed thoughout the layers, but still scan over this number. I'll keep the other hyperparameters in default, including the beta values for the adam optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of grid points: 729\n"
     ]
    }
   ],
   "source": [
    "n_hidden_layers = np.linspace(1, 9, 9, dtype=int)\n",
    "n_neurons = np.linspace(10, 90, 9, dtype=int)\n",
    "learning_rate = np.array([1e-3, 1e-2, 1e-1])\n",
    "batch_size = np.array([32, 64, 128])\n",
    "n_total = len(n_hidden_layers)*len(n_neurons)*len(learning_rate)*len(batch_size)\n",
    "print(f'total number of grid points: {n_total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jp/mambaforge/envs/ml-1/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/jp/mambaforge/envs/ml-1/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score = np.zeros(\n",
    "    (len(n_hidden_layers), \n",
    "    len(n_neurons),\n",
    "    len(batch_size),\n",
    "    len(learning_rate)\n",
    "    )\n",
    ")\n",
    "iteration = 1\n",
    "for i, n_hl in enumerate(n_hidden_layers):\n",
    "    for j, n_n in enumerate(n_neurons):\n",
    "        for k, bs in enumerate(batch_size):\n",
    "            for l, lr in enumerate(learning_rate):\n",
    "                #print(f'___________________')\n",
    "                #print(f'{iteration}/{n_total}\\t index: {i} {j} {k} {l}')\n",
    "                #print(f'n_hl = {n_hl}')\n",
    "                #print(f'n_n = {n_n}')\n",
    "                #print(f'lr = {lr}')\n",
    "                #print(f'bs = {bs}')\n",
    "                reg = MLPRegressor(\n",
    "                    hidden_layer_sizes = n_n*np.ones(n_hl, dtype=int),\n",
    "                    batch_size = bs,\n",
    "                    learning_rate_init = lr,\n",
    "                    random_state=0\n",
    "                ).fit(X_train, y_train)\n",
    "                score[i, j, k, l] = reg.score(X_val, y_val)\n",
    "                #print(f'score = {score[i, j, k, l]}')\n",
    "                iteration+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal hyperparameters based on grid scan:\n",
      "hidden layers: 7\n",
      "neurons per layer: 30\n",
      "batch size: 128\n",
      "initial learning rate: 0.001\n",
      "Optimized model score:  0.3464109209402946\n"
     ]
    }
   ],
   "source": [
    "max_index = np.unravel_index(score.argmax(), score.shape)\n",
    "n_hidden_layers_opt = n_hidden_layers[max_index[0]]\n",
    "n_neurons_opt = n_neurons[max_index[1]]\n",
    "batch_size_opt = batch_size[max_index[2]]\n",
    "learning_rate_opt = learning_rate[max_index[3]]\n",
    "print('optimal hyperparameters based on grid scan:')\n",
    "print(f'hidden layers: {n_hidden_layers_opt}')\n",
    "print(f'neurons per layer: {n_neurons_opt}')\n",
    "print(f'batch size: {batch_size_opt}')\n",
    "print(f'initial learning rate: {learning_rate_opt}')\n",
    "print(f'Optimized model score:  {score.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'optimized' model\n",
    "mlp_reg_opt = MLPRegressor(\n",
    "    hidden_layer_sizes = n_neurons_opt*np.ones(n_hidden_layers_opt, dtype=int),\n",
    "    batch_size = batch_size_opt,\n",
    "    learning_rate_init = learning_rate_opt,\n",
    "    random_state=0\n",
    ").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on validation dataset: 0.3464109209402946\n",
      "Score on test dataset: 0.27692386326911866\n",
      "Mean squared error on validation dataset: 0.5178870000084546\n",
      "Mean squared error on test dataset: 0.6373030745931618\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(f'Score on validation dataset: {mlp_reg_opt.score(X_val, y_val)}')\n",
    "print(f'Score on test dataset: {mlp_reg_opt.score(X_test, y_test)}')                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
    "print(f'Mean squared error on validation dataset: {mean_squared_error(y_val, mlp_reg_opt.predict(X_val))}')\n",
    "print(f'Mean squared error on test dataset: {mean_squared_error(y_test, mlp_reg_opt.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, I'll use the random forest regressor. The hyperparameters I'm going to scan through are the number of trees, maximum depth, minimum samples to split, and minimum samples at leaf. The rest will be left in their default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of grid points: 792\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [10, 20, 40, 80, 160, 320, 640, 1280]\n",
    "max_depth = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None]\n",
    "min_samples_split = [2, 4, 8]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "n_total = len(n_estimators)*len(max_depth)*len(min_samples_split)*len(min_samples_leaf)\n",
    "print(f'total number of grid points: {n_total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "score = np.zeros(\n",
    "    (len(n_estimators), \n",
    "    len(max_depth),\n",
    "    len(min_samples_split),\n",
    "    len(min_samples_leaf)\n",
    "    )\n",
    ")\n",
    "iteration = 1\n",
    "for i, n_t in enumerate(n_estimators):\n",
    "    for j, max_d in enumerate(max_depth):\n",
    "        for k, min_s_s in enumerate(min_samples_split):\n",
    "            for l, min_s_l in enumerate(min_samples_leaf):\n",
    "                #print(f'___________________')\n",
    "                #print(f'{iteration}/{n_total}\\t index: {i} {j} {k} {l}')\n",
    "                #print(f'n_t = {n_t}')\n",
    "                #print(f'max_d = {max_d}')\n",
    "                #print(f'min_s_s = {min_s_s}')\n",
    "                #print(f'min_s_l = {min_s_l}')\n",
    "                reg = RandomForestRegressor(\n",
    "                    n_estimators = n_t,\n",
    "                    max_depth = max_d,\n",
    "                    min_samples_split = min_s_s,\n",
    "                    min_samples_leaf = min_s_l, \n",
    "                    random_state=0\n",
    "                ).fit(X_train, y_train)\n",
    "                score[i, j, k, l] = reg.score(X_val, y_val)\n",
    "                #print(f'score = {score[i, j, k, l]}')\n",
    "                iteration+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal hyperparameters based on grid scan:\n",
      "number of trees: 160\n",
      "max depth: 20\n",
      "min samples to split: 2\n",
      "min samples at leaf: 1\n",
      "Optimized model score: 0.5171789817202856\n"
     ]
    }
   ],
   "source": [
    "max_index = np.unravel_index(score.argmax(), score.shape)\n",
    "n_estimators_opt = n_estimators[max_index[0]]\n",
    "max_depth_opt = max_depth[max_index[1]]\n",
    "min_samples_split_opt = min_samples_split[max_index[2]]\n",
    "min_samples_leaf_opt = min_samples_leaf[max_index[3]]\n",
    "print('optimal hyperparameters based on grid scan:')\n",
    "print(f'number of trees: {n_estimators_opt}')\n",
    "print(f'max depth: {max_depth_opt}')\n",
    "print(f'min samples to split: {min_samples_split_opt}')\n",
    "print(f'min samples at leaf: {min_samples_leaf_opt}')\n",
    "print(f'Optimized model score: {score.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg_opt = RandomForestRegressor(\n",
    "    n_estimators = n_estimators_opt,\n",
    "    max_depth = max_depth_opt,\n",
    "    min_samples_split = min_samples_split_opt,\n",
    "    min_samples_leaf = min_samples_leaf_opt, \n",
    "    random_state=0\n",
    ").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on validation dataset: 0.5171789817202856\n",
      "Score on test dataset: 0.4346579982043318\n",
      "Mean squared error on validation dataset: 0.382574826766753\n",
      "Mean squared error on test dataset: 0.4982797490316411\n"
     ]
    }
   ],
   "source": [
    "print(f'Score on validation dataset: {rf_reg_opt.score(X_val, y_val)}')\n",
    "print(f'Score on test dataset: {rf_reg_opt.score(X_test, y_test)}')                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
    "print(f'Mean squared error on validation dataset: {mean_squared_error(y_val, rf_reg_opt.predict(X_val))}')\n",
    "print(f'Mean squared error on test dataset: {mean_squared_error(y_test, rf_reg_opt.predict(X_test))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
